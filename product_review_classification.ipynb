{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Review Classification\n",
    "\n",
    "## Business Understanding\n",
    "Our company wants a tool that will automatically classify product reviews as _positive_ or _negative_ reviews, based on the features of the review.  This will help our Product team to perform more sophisticated analyses in the future to help ensure customer satisfaction.\n",
    "\n",
    "## Data Understanding\n",
    "We have a labeled collection of 20,000 product reviews, with an equal split of positive and negative reviews. The dataset contains the following features:\n",
    "\n",
    " - `ProductId` Unique identifier for the product\n",
    " - `UserId` Unqiue identifier for the user\n",
    " - `ProfileName` Profile name of the user\n",
    " - `HelpfulnessNumerator` Number of users who found the review helpful\n",
    " - `HelpfulnessDenominator` Number of users who indicated whether they found the review helpful or not\n",
    " - `Time` Timestamp for the review\n",
    " - `Summary` Brief summary of the review\n",
    " - `Text` Text of the review\n",
    " - `PositiveReview` 1 if this was labeled as a positive review, 0 if it was labeled as a negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Sequential, regularizers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>PositiveReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B002QWHJOU</td>\n",
       "      <td>A37565LZHTG1VH</td>\n",
       "      <td>C. Maltese</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1305331200</td>\n",
       "      <td>Awesome!</td>\n",
       "      <td>This is a great product. My 2 year old Golden ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000ESLJ6C</td>\n",
       "      <td>AMUAWXDJHE4D2</td>\n",
       "      <td>angieseashore</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1320710400</td>\n",
       "      <td>Was there a recipe change?</td>\n",
       "      <td>I have been drinking Pero ever since I was a l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004IJJQK4</td>\n",
       "      <td>AMHHNAFJ9L958</td>\n",
       "      <td>A M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1321747200</td>\n",
       "      <td>These taste so bland.</td>\n",
       "      <td>Look, each pack contains two servings of 120 c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId          UserId    ProfileName  HelpfulnessNumerator  \\\n",
       "0  B002QWHJOU  A37565LZHTG1VH     C. Maltese                     1   \n",
       "1  B000ESLJ6C   AMUAWXDJHE4D2  angieseashore                     1   \n",
       "2  B004IJJQK4   AMHHNAFJ9L958            A M                     0   \n",
       "\n",
       "   HelpfulnessDenominator        Time                     Summary  \\\n",
       "0                       1  1305331200                    Awesome!   \n",
       "1                       1  1320710400  Was there a recipe change?   \n",
       "2                       1  1321747200       These taste so bland.   \n",
       "\n",
       "                                                Text  PositiveReview  \n",
       "0  This is a great product. My 2 year old Golden ...               1  \n",
       "1  I have been drinking Pero ever since I was a l...               0  \n",
       "2  Look, each pack contains two servings of 120 c...               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has already been cleaned, so there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductId                 0\n",
       "UserId                    0\n",
       "ProfileName               0\n",
       "HelpfulnessNumerator      0\n",
       "HelpfulnessDenominator    0\n",
       "Time                      0\n",
       "Summary                   0\n",
       "Text                      0\n",
       "PositiveReview            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PositiveReview` is the target, and all other columns are features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"PositiveReview\", axis=1)\n",
    "y = df[\"PositiveReview\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "First, split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, prepare for modeling. The following `Pipeline` prepares all data for modeling.  It one-hot encodes the `ProductId`, applies a tf-idf vectorizer to the `Summary` and `Text`, keeps the numeric columns as-is, and drops all other columns.\n",
    "\n",
    "The following code may take up to 1 minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 11275)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_irrelevant_columns(X):\n",
    "    return X.drop([\"UserId\", \"ProfileName\"], axis=1)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"drop_columns\", FunctionTransformer(drop_irrelevant_columns)),\n",
    "    (\"transform_text_columns\", ColumnTransformer(transformers=[\n",
    "        (\"ohe\", OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\", sparse=False), [\"ProductId\"]),\n",
    "        (\"summary-tf-idf\", TfidfVectorizer(max_features=1000), \"Summary\"),\n",
    "        (\"text-tf-idf\", TfidfVectorizer(max_features=1000), \"Text\")\n",
    "    ], remainder=\"passthrough\"))\n",
    "])\n",
    "\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Fit a `RandomForestClassifier` with the best hyperparameters.  The following code may take up to 1 minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, min_samples_split=15, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    min_samples_split=15,\n",
    "    min_samples_leaf=1\n",
    ")\n",
    "rfc.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We are using _accuracy_ as our metric, which is the default metric in Scikit-Learn, so it is possible to just use the built-in `.score` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9826666666666667\n",
      "Test accuracy: 0.913\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", rfc.score(X_train_transformed, y_train))\n",
    "print(\"Test accuracy:\", rfc.score(X_test_transformed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      "[[7312  177]\n",
      " [  83 7428]]\n",
      "Test confusion matrix:\n",
      "[[2293  218]\n",
      " [ 217 2272]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train confusion matrix:\")\n",
    "print(confusion_matrix(y_train, rfc.predict(X_train_transformed)))\n",
    "print(\"Test confusion matrix:\")\n",
    "print(confusion_matrix(y_test, rfc.predict(X_test_transformed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Interpretation\n",
    "\n",
    "The tuned Random Forest Classifier model appears to be somewhat overfit on the training data, but nevertheless achieves 91% accuracy on the test data.  Of the 9% of mislabeled comments, about half are false positives and half are false negatives.\n",
    "\n",
    "Because this is a balanced dataset, 91% accuracy is a substantial improvement over a 50% baseline.  This model is ready for production use for decision support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "#Instantiate a StandardScaler object\n",
    "ss = StandardScaler()\n",
    "#Generate a new X_train_transformed_scaled by calling .fit_transform on the scaler object,\n",
    "#after you have called .fit_transform on the pipeline\n",
    "X_train_transformed_scaled = ss.fit_transform(X_train_transformed)\n",
    "#Generate a new X_test_transformed_scaled by calling .transform on the scaler object,\n",
    "#after you have called .transform on the pipeline\n",
    "X_test_transformed_scaled = ss.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.3040 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0325 - accuracy: 0.0073\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.0063 - accuracy: 0.0572\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.0032 - accuracy: 0.1386\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 5.5151e-04 - accuracy: 0.1761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x152b45670>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model = Sequential()\n",
    "#Add an input Dense layer. You'll need to specify a input_shape = (11275,) \n",
    "#because this is the number of features of the transformed dataset.\n",
    "model.add(Dense(units=64, activation=\"relu\", input_shape=(11275,)))\n",
    "#Add 2 Dense hidden layers. They can have any number of units, but keep in mind that more units will require more processing power. \n",
    "#We recommend an initial units of 64 for processing power reasons.\n",
    "model.add(Dense(units=64, activation=\"relu\"))\n",
    "model.add(Dense(units=64, activation=\"relu\"))\n",
    "#Add a final Dense output layer. This layer must have exactly 1 unit because we are doing a binary prediction task.\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "#Compile the Sequential model\n",
    "model.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics=[\"Accuracy\"])\n",
    "#Fit the Sequential model on the preprocessed training data (X_train_transformed_scaled) \n",
    "#with a bbatch_size of 50 and epochs of 5 for processing power reasons.\n",
    "model.fit(X_train_transformed_scaled, y_train, batch_size=50, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Model Tuning + Feature Engineering\n",
    "If you are running out of time, skip this step.\n",
    "\n",
    "Tune the neural network model to improve performance. This could include steps such as increasing the units, changing the activation functions, or adding regularization.\n",
    "\n",
    "We recommend using using a validation_split of 0.1 to understand model performance without utilizing the test holdout set.\n",
    "\n",
    "You can also return to the preprocessing phase, and add additional features to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.3023 - accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.0318 - accuracy: 0.0110\n",
      "Epoch 3/20\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.0074 - accuracy: 0.0959\n",
      "Epoch 4/20\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.2241\n",
      "Epoch 5/20\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0990e-04 - accuracy: 0.2911\n",
      "Epoch 6/20\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 7.3602e-05 - accuracy: 0.3179\n",
      "Epoch 7/20\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 4.2280e-04 - accuracy: 0.3275\n",
      "Epoch 8/20\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.5728e-04 - accuracy: 0.3772\n",
      "Epoch 9/20\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 6.1975e-04 - accuracy: 0.3727\n",
      "Epoch 10/20\n",
      "300/300 [==============================] - 4s 15ms/step - loss: 0.0085 - accuracy: 0.3265\n",
      "Epoch 11/20\n",
      "300/300 [==============================] - 5s 15ms/step - loss: 0.0173 - accuracy: 0.1575\n",
      "Epoch 12/20\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0068 - accuracy: 0.1971\n",
      "Epoch 13/20\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 8.5334e-04 - accuracy: 0.2815\n",
      "Epoch 14/20\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0013 - accuracy: 0.3995\n",
      "Epoch 15/20\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.1811e-05 - accuracy: 0.4257\n",
      "Epoch 16/20\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 7.7072e-06 - accuracy: 0.4299\n",
      "Epoch 17/20\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 4.9089e-06 - accuracy: 0.4338\n",
      "Epoch 18/20\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.5786e-06 - accuracy: 0.4371\n",
      "Epoch 19/20\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.7413e-06 - accuracy: 0.4406\n",
      "Epoch 20/20\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1593e-06 - accuracy: 0.4448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15383eaf0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model2 = Sequential()\n",
    "#Add an input Dense layer. You'll need to specify a input_shape = (11275,) \n",
    "model2.add(Dense(units=64, activation=\"relu\", input_shape=(11275,)))\n",
    "#Add 2 Dense hidden layers. They can have any number of units, but keep in mind that more units will require more processing power. \n",
    "#We recommend an initial units of 64 for processing power reasons.\n",
    "model2.add(Dense(units=128, activation=\"relu\"))\n",
    "model2.add(Dense(units=128, activation=\"relu\"))\n",
    "#Add a final Dense output layer. This layer must have exactly 1 unit because we are doing a binary prediction task.\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "#Compile the Sequential model\n",
    "model2.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics=[\"Accuracy\"])\n",
    "#Fit the Sequential model on the preprocessed training data (X_train_transformed_scaled) \n",
    "#with a bbatch_size of 50 and epochs of 5 for processing power reasons.\n",
    "model2.fit(X_train_transformed_scaled, y_train, batch_size=50, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.3849 - accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.1028 - accuracy: 0.0206\n",
      "Epoch 3/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0658 - accuracy: 0.1128\n",
      "Epoch 4/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0469 - accuracy: 0.1573\n",
      "Epoch 5/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0328 - accuracy: 0.2238\n",
      "Epoch 6/25\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.0227 - accuracy: 0.2382\n",
      "Epoch 7/25\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.0158 - accuracy: 0.2199\n",
      "Epoch 8/25\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.0110 - accuracy: 0.1895\n",
      "Epoch 9/25\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.0076 - accuracy: 0.1586\n",
      "Epoch 10/25\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.0053 - accuracy: 0.1275\n",
      "Epoch 11/25\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.1147\n",
      "Epoch 12/25\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0236 - accuracy: 0.1163\n",
      "Epoch 13/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0232 - accuracy: 0.1427\n",
      "Epoch 14/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0094 - accuracy: 0.2312\n",
      "Epoch 15/25\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.0048 - accuracy: 0.3246\n",
      "Epoch 16/25\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.2162\n",
      "Epoch 17/25\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.2636\n",
      "Epoch 18/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0023 - accuracy: 0.2588\n",
      "Epoch 19/25\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.0019 - accuracy: 0.2318\n",
      "Epoch 20/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0015 - accuracy: 0.2122\n",
      "Epoch 21/25\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.1904\n",
      "Epoch 22/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0011 - accuracy: 0.1695\n",
      "Epoch 23/25\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.0035 - accuracy: 0.1565\n",
      "Epoch 24/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0036 - accuracy: 0.1955\n",
      "Epoch 25/25\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.0051 - accuracy: 0.1947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x154854e80>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model3 = Sequential()\n",
    "#Add an input Dense layer. You'll need to specify a input_shape = (11275,) \n",
    "#because this is the number of features of the transformed dataset.\n",
    "model3.add(Dense(units=64, activation=\"relu\", input_shape=(11275,)))\n",
    "#Add Dense hidden layers.\n",
    "model3.add(Dense(units=128, activation=\"relu\", kernel_regularizer=regularizers.l1(0.0001)))\n",
    "model3.add(Dense(units=128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model3.add(Dense(units=64, activation=\"relu\"))\n",
    "#Add a final Dense output layer. This layer must have exactly 1 unit because we are doing a binary prediction task.\n",
    "model3.add(Dense(1, activation=\"sigmoid\"))\n",
    "#Compile the Sequential model\n",
    "model3.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics=[\"Accuracy\"])\n",
    "#Fit the Sequential model on the preprocessed training data (X_train_transformed_scaled) \n",
    "model.fit(X_train_transformed_scaled, y_train, batch_size=50, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "300/300 [==============================] - 5s 17ms/step - loss: 0.2993 - accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0336 - accuracy: 0.0082\n",
      "Epoch 3/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0074 - accuracy: 0.0838\n",
      "Epoch 4/25\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.0030 - accuracy: 0.1888\n",
      "Epoch 5/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0011 - accuracy: 0.2401\n",
      "Epoch 6/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 5.2429e-04 - accuracy: 0.3025\n",
      "Epoch 7/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0013 - accuracy: 0.2797\n",
      "Epoch 8/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 8.3579e-05 - accuracy: 0.3473\n",
      "Epoch 9/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 4.9873e-05 - accuracy: 0.3853\n",
      "Epoch 10/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.8031e-05 - accuracy: 0.4021\n",
      "Epoch 11/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 8.1947e-06 - accuracy: 0.4140\n",
      "Epoch 12/25\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 3.9873e-06 - accuracy: 0.4256\n",
      "Epoch 13/25\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.7116e-06 - accuracy: 0.4356\n",
      "Epoch 14/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1233e-06 - accuracy: 0.4429\n",
      "Epoch 15/25\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 1.6002e-06 - accuracy: 0.4491\n",
      "Epoch 16/25\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 1.2200e-06 - accuracy: 0.4543\n",
      "Epoch 17/25\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.0557e-06 - accuracy: 0.4593\n",
      "Epoch 18/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 7.5361e-07 - accuracy: 0.4621\n",
      "Epoch 19/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 5.9983e-07 - accuracy: 0.4653\n",
      "Epoch 20/25\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.8951e-07 - accuracy: 0.4679\n",
      "Epoch 21/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.9983e-07 - accuracy: 0.4707\n",
      "Epoch 22/25\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.1101e-07 - accuracy: 0.4736\n",
      "Epoch 23/25\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.8063e-07 - accuracy: 0.4761\n",
      "Epoch 24/25\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1437e-07 - accuracy: 0.4780\n",
      "Epoch 25/25\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.7882e-07 - accuracy: 0.4803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x154996700>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model4 = Sequential()\n",
    "#Add an input Dense layer. You'll need to specify a input_shape = (11275,) \n",
    "model4.add(Dense(units=64, activation=\"relu\", input_shape=(11275,)))\n",
    "#Add Dense hidden layers.\n",
    "model4.add(Dense(units=128, activation=\"relu\"))\n",
    "model4.add(Dense(units=256, activation=\"relu\"))\n",
    "model4.add(Dropout(0.025))\n",
    "model4.add(Dense(units=16, activation=\"relu\"))\n",
    "#Add a final Dense output layer. This layer must have exactly 1 unit because we are doing a binary prediction task.\n",
    "model4.add(Dense(1, activation=\"sigmoid\"))\n",
    "#Compile the Sequential model\n",
    "model4.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics=[\"Accuracy\"])\n",
    "#Fit the Sequential model on the preprocessed training data (X_train_transformed_scaled) \n",
    "model4.fit(X_train_transformed_scaled, y_train, batch_size=50, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Model Evaluation\n",
    "\n",
    "Choose a final Sequential model, add layers, and compile. Fit the model on the preprocessed training data (X_train_transformed_scaled, y_train) and evaluate on the preprocessed testing data (X_test_transformed_scaled, y_test) using accuracy_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 0.3017 - accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 0.0347 - accuracy: 0.0251\n",
      "Epoch 3/25\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.0077 - accuracy: 0.1159\n",
      "Epoch 4/25\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 0.0037 - accuracy: 0.2119\n",
      "Epoch 5/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0011 - accuracy: 0.2677\n",
      "Epoch 6/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 6.1089e-04 - accuracy: 0.3644\n",
      "Epoch 7/25\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.0010 - accuracy: 0.3363\n",
      "Epoch 8/25\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 4.4987e-05 - accuracy: 0.2843\n",
      "Epoch 9/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 1.6354e-05 - accuracy: 0.3361\n",
      "Epoch 10/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 9.9860e-06 - accuracy: 0.3597\n",
      "Epoch 11/25\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 6.4952e-06 - accuracy: 0.3807\n",
      "Epoch 12/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 4.7941e-06 - accuracy: 0.3916\n",
      "Epoch 13/25\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 3.4291e-06 - accuracy: 0.4045\n",
      "Epoch 14/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 2.6457e-06 - accuracy: 0.4132\n",
      "Epoch 15/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1302e-06 - accuracy: 0.4194\n",
      "Epoch 16/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 1.7070e-06 - accuracy: 0.4271\n",
      "Epoch 17/25\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 1.3107e-06 - accuracy: 0.4355\n",
      "Epoch 18/25\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0474e-06 - accuracy: 0.4393\n",
      "Epoch 19/25\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 7.9700e-07 - accuracy: 0.4428\n",
      "Epoch 20/25\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 6.5824e-07 - accuracy: 0.4471\n",
      "Epoch 21/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 6.1451e-07 - accuracy: 0.4512\n",
      "Epoch 22/25\n",
      "300/300 [==============================] - 4s 15ms/step - loss: 4.5283e-07 - accuracy: 0.4550\n",
      "Epoch 23/25\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 3.8292e-07 - accuracy: 0.4575\n",
      "Epoch 24/25\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8603e-07 - accuracy: 0.4612\n",
      "Epoch 25/25\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.3935e-07 - accuracy: 0.4642\n"
     ]
    }
   ],
   "source": [
    "#Our best model was model number 4 (model4) as seen bellow.\n",
    "\n",
    "#Instantiate a Sequential model\n",
    "model4 = Sequential()\n",
    "#Add an input Dense layer. You'll need to specify a input_shape = (11275,) \n",
    "model4.add(Dense(units=64, activation=\"relu\", input_shape=(11275,)))\n",
    "#Add Dense hidden layers.\n",
    "model4.add(Dense(units=128, activation=\"relu\"))\n",
    "model4.add(Dense(units=256, activation=\"relu\"))\n",
    "model4.add(Dropout(0.025))\n",
    "model4.add(Dense(units=16, activation=\"relu\"))\n",
    "#Add a final Dense output layer. This layer must have exactly 1 unit because we are doing a binary prediction task.\n",
    "model4.add(Dense(1, activation=\"sigmoid\"))\n",
    "#Compile the Sequential model\n",
    "model4.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics=[\"Accuracy\"])\n",
    "#Fit the Sequential model on the preprocessed training data (X_train_transformed_scaled) \n",
    "model_data = model4.fit(X_train_transformed_scaled, y_train, batch_size=50, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 5ms/step - loss: 2.0787e-07 - accuracy: 0.4661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0786725940524775e-07, 0.4660666584968567]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the loss and accuracy for the training set \n",
    "results_train = model4.evaluate(X_train_transformed_scaled, y_train)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8253 - accuracy: 0.3216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.825266420841217, 0.3215999901294708]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the loss and accuracy for the test set \n",
    "results_test = model4.evaluate(X_test_transformed_scaled, y_test)\n",
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = model_data.history\n",
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Technical Communication\n",
    "\n",
    "Write a paragraph explaining whether Northwind Trading Company should switch to using your new neural network model, or continue to use the Random Forest Classifier. Beyond a simple comparison of performance, try to take into consideration additional considerations such as:\n",
    "\n",
    "Computational complexity/resource use\n",
    "\n",
    "Anticipated performance on future datasets (how might the data change over time?)\n",
    "\n",
    "Types of mistakes made by the two kinds of models\n",
    "\n",
    "\n",
    "You can make guesses or inferences about these considerations.\n",
    "Include at least one visualization comparing the two types of models. Possible points of comparison could include ROC curves, colorized confusion matrices, or time needed to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_values = model_dict['accuracy'] \n",
    "epochs = range(1, len(model_dict['loss']) + 1)\n",
    "\n",
    "plt.plot(epochs, acc_values, 'r', label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I have been able to work on I would recommend to keep using the Random Forest Model for now. While it is overfitting we can adjust some hyperparameters to adjust this.\n",
    "\n",
    "However I would continue to invest in a Machine Learning model. While our final model scored right under random chance, our model was still improving. We only spent an hour looking at different parameters, if given more time we could improve our score greatly. We can see proof of this in our Training Accuracy graph above. We can see that our best model was still improving and had not flattened out yet. Given more time I would also like to see what was causing the spike at the 6 epoch level. \n",
    "\n",
    "I am confident that given more time, we could build a model that does not overfit like the random forest and therefore performs better on different datasets that have a similar theme of recommending a product or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
